{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "Load POIs\n",
      "processing csv file!!\n",
      "add poi location!\n",
      "save file\n"
     ]
    }
   ],
   "source": [
    "# %load impact.py\n",
    "%load_ext line_profiler\n",
    "import json\n",
    "import math\n",
    "import multiprocessing as mp\n",
    "\n",
    "import numpy as np\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "from haversine import haversine\n",
    "import networkx as nx\n",
    "from shapely.geometry import Point\n",
    "import os\n",
    "DISTANCE = 50\n",
    "\n",
    "\n",
    "def get_point(point):\n",
    "    return(point.x, point.y)\n",
    "\n",
    "\n",
    "def impact(point1, point2):\n",
    "    imp = 0.5 + \\\n",
    "        (0.5 * math.cos((math.pi * m_haversine(point1, point2) / DISTANCE)))\n",
    "    return imp\n",
    "\n",
    "\n",
    "def poi_impact(point):\n",
    "    tmp = (None, 0, None, None)\n",
    "    point = Point(point)\n",
    "    poi_list = pois_from_point(point, distance=(DISTANCE+5))\n",
    "    # get nearest POI and impact\n",
    "    for index, poi in poi_list.geometry.centroid.items():\n",
    "        if DISTANCE >= m_haversine((point.x, point.y), (poi.x, poi.y)):\n",
    "            imp = impact((point.x, point.y), (poi.x, poi.y))\n",
    "            if tmp[1] < imp:\n",
    "                amenity = poi_list.loc[index].amenity\n",
    "                tmp = (poi, imp, index, amenity)\n",
    "    return tmp\n",
    "\n",
    "def m_haversine(point1, point2):\n",
    "    return (haversine(point1, point2) * 1000)\n",
    "\n",
    "def pois_from_point(point, distance):\n",
    "    dist = p_list.apply(lambda place: place.distance(point)*100000)\n",
    "    return all_pois[dist <= distance]\n",
    "    # xmin, ymin, xmax, ymax= ox.bbox_from_point(point=(point.y, point.x), distance=distance)\n",
    "    # dist = p_list.cx[xmin:xmax, ymin:ymax].index\n",
    "    # return all_pois.loc[dist]\n",
    "\n",
    "def _apply_df(args):\n",
    "    df, func, num, kwargs = args\n",
    "    return num, df.apply(func, **kwargs)\n",
    "\n",
    "\n",
    "def apply_by_multiprocessing(df, func, **kwargs):\n",
    "    workers = (mp.cpu_count()-1)\n",
    "    pool = mp.Pool(processes=(workers))\n",
    "    result = pool.map(_apply_df, [(d, func, i, kwargs)\n",
    "                                  for i, d in enumerate(np.array_split(df, workers))])\n",
    "    pool.close()\n",
    "    result = sorted(result, key=lambda x: x[0])\n",
    "    return pd.concat([i[1] for i in result])\n",
    "\n",
    "def get_pois(place):\n",
    "    poi_file = \"%s_pois.pkl\" % place.replace(' ', '_')\n",
    "    if os.path.exists(poi_file):\n",
    "        return pd.read_pickle(poi_file)\n",
    "    else:\n",
    "        return ox.pois_from_place(place=place)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print('Load POIs')\n",
    "    place = \"San Francisco\"\n",
    "    all_pois = get_pois(place)\n",
    "    p_list = all_pois.geometry.centroid\n",
    "\n",
    "    print('processing csv file!!')\n",
    "    filedir = \"/Users/lucasso 1/Downloads/view.json\"\n",
    "    tweets = list()\n",
    "    with open(filedir) as data_file:\n",
    "        for line in data_file:\n",
    "            tweet = json.loads(line)\n",
    "            tweets.append([tweet['created_at'], tweet['user_screen_name'],\n",
    "                           json.loads(tweet['st_asgeojson'])['coordinates']])\n",
    "\n",
    "    df = pd.DataFrame(tweets[:100])\n",
    "    df.rename(columns={0: 'timestamp', 1: 'user', 2: 'location'}, inplace=True)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    del tweets\n",
    "\n",
    "    # add poi location and impact for each tweet\n",
    "    print('add poi location!')\n",
    "    %lprun -f pois_from_point df['poi_loc'], df['impact'], df['poi_id'], df['amenity'] = zip(*df.apply(lambda row: poi_impact(row['location']), axis=1))\n",
    "    #df['poi_loc'], df['impact'], df['poi_id'], df['amenity'] = zip(\n",
    "    #    *apply_by_multiprocessing(df['location'], poi_impact))\n",
    "\n",
    "    df = df.drop(df[pd.isna(df.poi_id)].index)\n",
    "\n",
    "    df.set_index(['timestamp'], inplace=True)\n",
    "    df['hour'] = df.index.hour\n",
    "\n",
    "    print('save file')\n",
    "    #df.to_pickle('poi_tw.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
